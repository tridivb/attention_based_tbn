# Dataset Parameters
DATA:
  DATA_DIR: "/path/to/dataset/root"
  DATASET: "dataset_name"
  # Flag to turn on/off RGB
  USE_RGB: True
  # RGB directory prefix. Absolute path will look like DATA_DIR/RGB_DIR_PREFIX
  RGB_DIR_PREFIX: "<rgb/prefix>"
  # Flag to turn on/off Flow
  USE_FLOW: True
  # Flag to turn on/off reading Flow data from pickle files. Pickled file can speedup data loading
  READ_FLOW_PICKLE: True
  # RGB directory prefix. Absolute path will look like DATA_DIR/FLOW_DIR_PREFIX
  FLOW_DIR_PREFIX: "<flow/prefix>"
  # Flag to turn on/off Flow
  USE_AUDIO: True
  # Flag to turn on/off reading Audio data from pickle files. Pickled file can speedup data loading
  READ_AUDIO_PICKLE: True
  # RGB directory prefix. Absolute path will look like DATA_DIR/AUDIO_DIR_PREFIX
  AUDIO_DIR_PREFIX: "<audio/prefix>"
  # Input video fps
  VID_FPS: 60
  OUT_DIR: "/path/to/output/directory/"
  # File type of RGB and Flow file
  FRAME_FILE_EXT: "jpg"
  # File type of Audio files
  AUDIO_FILE_EXT: "wav"
  # Number of sequential flow files to stack = FLOW_WIN_LENGTH * 2 
  FLOW_WIN_LENGTH: 5
  # Audio sampling rate
  SAMPLING_RATE: 24000
  # Length of temporal window to sample audio from the untrimmed sample
  AUDIO_LENGTH: 1.279
  # Mean of RGB frames
  RGB_MEAN: [0.408, 0.459, 0.502]
  # Standard Deviation of RGB frames
  RGB_STD: [1.0, 1.0, 1.0]
  # Mean of Flow frames
  FLOW_MEAN: [0.502]
  # Standard Deviation of Flow frames
  FLOW_STD: [1.0]
  # Scale and Crop sizes for RGB and Flow frames
  TRAIN_SCALE_SIZE: 256
  TRAIN_CROP_SIZE: 224
  TEST_SCALE_SIZE: 256
  TEST_CROP_SIZE: 224
  # Set manual seed for reproducibility
  MANUAL_SEED: 0
# Model Parameters
MODEL:
  # Model architecture
  ARCH: "bninception"
  # Flag to Freeze weights of base model
  FREEZE_BASE: True
  # Mode of freezing
  FREEZE_MODE: "partialbn"
  # Classes and their corresponding counts for the final linear layers
  NUM_CLASSES: { verb: 125, noun: 352 }
  # Aggregation type of the temporal windows for a trimmed segment
  AGG_TYPE: "avg"
  # Dropout probability for the fusion layer
  FUSION_DROPOUT: 0.5
  # Loss function to use
  LOSS_FN: "CrossEntropy"
  CHECKPOINT_DIR: "/path/to/save/model/weights"
# Train Parameters
TRAIN:
  # Flag to turn on/off training
  TRAIN_ENABLE: True
  # Annotation file for both training and validation
  ANNOTATION_FILE: "/path/to/train/annotation/file"
  VID_LIST: "/path/to/video/list/to/process/for/training"
  # Optimizer type
  OPTIM: "sgd"
  # Training Batch size
  BATCH_SIZE: 48
  # Number of epochs
  EPOCHS: 30
  # Learning rate
  LR: 1e-2
  # SGD Momentum. Only usable with SGD optimizer
  MOMENTUM: 0.9
  # Adam weight decay. Only usable with Adam optimizer
  WEIGHT_DECAY: 0
  # Epoch numbers at which to decay Learning rate. Only works with SGD optimizer
  LR_STEPS: [20]
  # Learning decay rate. Only works with SGD optimizer
  LR_DECAY: 1e-1
  # Gradient clipping threshold
  CLIP_GRAD: 20
  # Number of temporal segments to sample for each trimmed video segment
  NUM_SEGMENTS: 3
  # Pretrained weights to load before training.
  PRE_TRAINED: ""
# Validation Parameters
VAL:
  # Flag to turn on/off validation
  VAL_ENABLE: True
  VID_LIST: "/path/to/video/list/to/process/for/validation"
  # Validation Batch size
  BATCH_SIZE: 6
  # Top k accuracies to compute
  TOPK: [1, 5]
  # Number of temporal segments to sample for each trimmed video segment
  NUM_SEGMENTS: 25
  # Test Parameters
TEST:
  # Flag to turn on/off testing
  TEST_ENABLE: False
  # For testing, multiple annotation files can be provided like ["file1", "file2", ...]
  ANNOTATION_FILE: ["/path/to/test/annotation/file"]
  # Leave the vid list blank if you want to process all the annotations for testing. 
  # If you need a select few, use a list like in validation
  VID_LIST: ""
  # Test Batch size
  BATCH_SIZE: 6
  # Top k accuracies to compute
  TOPK: [1, 5]
  # Number of temporal segments to sample for each trimmed video segment
  NUM_SEGMENTS: 25
  # Flag to turn on/off saving results to a json file
  SAVE_RESULTS: False
  # Output json file to save results to. File will be saved under OUT_DIR. 
  # The number of results file must be equal to the number of files provided in TEST.ANNOTATION above
  # File names can also include subdirectories eg. "rgb/results.json"
  RESULTS_FILE: ["<file_name>.json"]
  # Pretrained weights to load for Testing. Either the train or test PRE_TRAINED have to be set for testing to be proceed.
  PRE_TRAINED: ""
# Misc
# Number of CPU workers for the Pytorch dataloader
NUM_WORKERS: 8
# Number of GPUs to use
NUM_GPUS: 1
# GPU IDs to use (optional).
GPU_IDS: []
