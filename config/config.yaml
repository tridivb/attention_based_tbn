# Dataset Parameters
DATA:
  DATA_DIR: "/media/data/tridiv/epic"
  FRAME_DIR_PREFIX: "symlinks"
  READ_AUDIO_PICKLE: True
  AUDIO_DIR_PREFIX: "audio_pickle"
  DATASET: "epic"
  USE_RGB: True
  USE_FLOW: True
  USE_AUDIO: True
  OUT_DIR: "/media/data/tridiv/thesis/attention_based_tbn/"
  FRAME_FILE_EXT: "jpg"
  AUDIO_FILE_EXT: "wav"
  FLOW_WIN_LENGTH: 5
  SAMPLING_RATE: 24000
  AUDIO_LENGTH: 1.28
  RGB_MEAN: [0.408, 0.459, 0.502]
  RGB_STD: [1.0, 1.0, 1.0]
  FLOW_MEAN: [0.502]
  FLOW_STD: [1.0]
  TRAIN_SCALE_SIZE: 256
  TRAIN_CROP_SIZE: 224
  TEST_SCALE_SIZE: 256
  TEST_CROP_SIZE: 256
  MANUAL_SEED: 0
# Model Parameters
MODEL:
  ARCH: "bninception"
  NUM_CLASSES: {
    verb: 127,
    noun: 352
  }
  AGG_TYPE: "avg"
  FUSION_DROPOUT: 0.5
  USE_SOFTMAX: True
  LOSS_FN: "CrossEntropy"
  CHECKPOINT_DIR: "/media/remote_home/tridiv/attention_based_tbn/weights"
# Train Parameters
TRAIN:
  TRAIN_ENABLE: True
  ANNOTATION_FILE: "/media/data/tridiv/epic_kitchens/annotations/EPIC_train_action_labels.csv"
  VID_LIST: "./data/train_split.txt"
  OPTIM: "sgd"
  BATCH_SIZE: 22
  EPOCHS: 80
  LR: 1e-2
  MOMENTUM: 0.9
  WEIGHT_DECAY: 0
  LR_STEPS: [20, 40]
  LR_DECAY: 1e-6
  FREEZE_BASE: False
  FREEZE_FUSION: False
  NUM_SEGMENTS: 3
  PRE_TRAINED: ""
# Validation Parameters
VAL:
  VID_LIST: "./data/val_split.txt"
  BATCH_SIZE: 48
  PRE_TRAINED: ""
  TOPK: [1, 5]
  NUM_SEGMENTS: 25
  # Test Parameters
TEST:
  TEST_ENABLE: False
  # ANNOTATION_FILE: "/media/data/tridiv/epic_kitchens/annotations/EPIC_test_s2_timestamps.csv"
  ANNOTATION_FILE: "/media/data/tridiv/epic_kitchens/annotations/EPIC_train_action_labels.csv"
  VID_LIST: "./data/val_split.txt"
  BATCH_SIZE: 64
  PRE_TRAINED: "/media/remote_home/tridiv/attention_based_tbn/weights/epic_tbn_bninception_RGB_Flow_Audio.pth"
  TOPK: [1, 5]
  NUM_SEGMENTS: 25
  SAVE_RESULTS:  False
  RESULTS_FILE: "unseen.json"
  PRE_TRAINED: ""
# Misc
NUM_WORKERS: 8 
NUM_GPUS: 1
GPU_IDS: []
